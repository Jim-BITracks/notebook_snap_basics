{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "2d0fd733-e104-40b2-b21f-85cdac9f46ca"
            },
            "source": [
                "# Snowflake Metadata Refresh Setup"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import Python Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import snowflake.connector\n",
                "import os\n",
                "import sys\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pyarrow as pa\n",
                "# pd.set_option('max_columns', 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set Snowflake Variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# snowflake connection variables\n",
                "snowflake_user = 'JMILLER'\n",
                "snowflake_password = os.environ['BISNOWPASS']\n",
                "snowflake_account = 'eh69371.east-us-2.azure'\n",
                "snowflake_role = 'SYSADMIN'\n",
                "snowflake_warehouse = 'COMPUTE_WH'\n",
                "\n",
                "# # database and schema for metadata objects\n",
                "snowflake_database = 'UTIL_DB'\n",
                "snowflake_schema = 'METADATA'\n",
                "\n",
                "print('Using Notebook Variables:')\n",
                "print('snowflake_user: ' + snowflake_user)\n",
                "print('snowflake_password: ' + '***************')\n",
                "print('snowflake_account: ' + snowflake_account)\n",
                "print('snowflake_role: ' + snowflake_role)\n",
                "print('snowflake_warehouse: ' + snowflake_warehouse)\n",
                "print('snowflake_database: ' + snowflake_database)\n",
                "print('snowflake_schema: ' + snowflake_schema)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set Notebook Variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# notebook variables\n",
                "src_database = 'UTIL_DB'\n",
                "tgt_database = 'UTIL_DB'\n",
                "src_schema = 'INFORMATION_SCHEMA'\n",
                "tgt_schema = 'METADATA'\n",
                "src_table = 'DATABASES'\n",
                "tgt_table = 'D_DATABASES'\n",
                "added_dim_column_names_tag = 'standard_uc'\n",
                "natural_key_columns = 'DATABASE_NAME'\n",
                "type_2_columns = 'DATABASE_OWNER,RETENTION_TIME'\n",
                "type_0_columns = ''\n",
                "\n",
                "src_table_full = '\"' + src_database + '\".\"' + src_schema + '\".\"' + src_table + '\"'\n",
                "if not src_database:\n",
                "        src_table_full = '\"' + src_schema + '\".\"' + src_table + '\"'\n",
                "\n",
                "tgt_table_full = '\"' + tgt_database + '\".\"' + tgt_schema + '\".\"' + tgt_table + '\"'\n",
                "if not tgt_database:\n",
                "        src_table_full = '\"' + tgt_schema + '\".\"' + tgt_table + '\"'\n",
                "\n",
                "print('Using Notebook Variables:')\n",
                "print('src_table_full: ' + src_table_full)\n",
                "print('tgt_table_full: ' + tgt_table_full)\n",
                "print('added_dim_column_names_tag: ' + added_dim_column_names_tag)\n",
                "print('natural_key_columns: ' + natural_key_columns)\n",
                "print('type_2_columns: ' + type_2_columns)\n",
                "print('type_0_columns: ' + type_0_columns)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check for Required values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not src_schema:\n",
                "    sys.exit(\"src_schema is required\")\n",
                "\n",
                "if not tgt_schema:\n",
                "    sys.exit(\"tgt_schema is required\")\n",
                "\n",
                "if not src_table:\n",
                "    sys.exit(\"src_table is required\")\n",
                "\n",
                "if not tgt_table:\n",
                "    sys.exit(\"tgt_table is required\")\n",
                "\n",
                "if not added_dim_column_names_tag:\n",
                "    sys.exit(\"added_dim_column_names_tag is required\")\n",
                "\n",
                "if not natural_key_columns:\n",
                "    sys.exit(\"natural_key_columns is required\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Establish Snowflake Connection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "bdca4781-9494-4f61-940d-9c004032a582"
            },
            "outputs": [],
            "source": [
                "ctx = snowflake.connector.connect(\n",
                "    user = snowflake_user,\n",
                "    password = snowflake_password,\n",
                "    account = snowflake_account,\n",
                "    role = snowflake_role,\n",
                "    warehouse = snowflake_warehouse\n",
                "    )\n",
                "cur = ctx.cursor()\n",
                "\n",
                "# Return Client\n",
                "cur.execute(\"select CURRENT_CLIENT()\")\n",
                "one_row = cur.fetchone()\n",
                "print('Snowflake Connection Successful')\n",
                "print(one_row[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set Snowflake Database and Schema Context"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = \"use database \" + snowflake_database + \";\"\n",
                "print(sql)\n",
                "cur.execute(sql)\n",
                "\n",
                "sql = \"use schema \" + snowflake_schema + \";\"\n",
                "print(sql)\n",
                "cur.execute(sql)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get names for supplemental dimension columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = \"\"\"\n",
                "SELECT ROW_IS_CURRENT, ROW_EFFECTIVE_DATE, ROW_EXPIRATION_DATE, ROW_INSERT_DATE, ROW_UPDATE_DATE \n",
                "  FROM ADDED_DIM_COLUMN_NAMES \n",
                " WHERE ADDED_DIM_COLUMN_NAMES_TAG  = '\"\"\" + added_dim_column_names_tag + \"\"\"' \n",
                "\"\"\"\n",
                "print(sql)\n",
                "cur.execute(sql)\n",
                "one_row = cur.fetchone()\n",
                "row_is_current = one_row[0]\n",
                "row_effective_date = one_row[1]\n",
                "row_expiration_date = one_row[2]\n",
                "row_insert_date = one_row[3]\n",
                "row_update_date = one_row[4]\n",
                "\n",
                "print('row_is_current:', row_is_current)\n",
                "print('row_effective_date:', row_effective_date)\n",
                "print('row_expiration_date:', row_expiration_date)\n",
                "print('row_insert_date:', row_insert_date)\n",
                "print('row_update_date:', row_update_date)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Natural key select and joins"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = \"\"\"\n",
                "WITH base AS\n",
                "(\n",
                "SELECT DISTINCT TOP 1000 ORDINAL_POSITION, COLUMN_NAME\n",
                "  FROM \"\"\" + src_database + \"\"\".INFORMATION_SCHEMA.\"COLUMNS\"\n",
                " WHERE COLUMN_NAME IN (select trim(value) from table(split_to_table('\"\"\" + natural_key_columns + \"\"\"', ',')))\n",
                "   AND TABLE_SCHEMA = '\"\"\" + src_schema + \"\"\"'\n",
                "   AND TABLE_NAME = '\"\"\" + src_table + \"\"\"'\n",
                ")\n",
                "SELECT TRIM(LISTAGG(' s.' || COLUMN_NAME || ', '), ', ') || ' ' AS nat_key_select\n",
                "\t , REPLACE(REPLACE(LISTAGG(' r.' || COLUMN_NAME || ' = s.' || COLUMN_NAME  || ' AND ~') || '~','AND ~~'), '~')  AS nat_key_join\n",
                "\t , REPLACE(REPLACE(LISTAGG(' t1.' || COLUMN_NAME || ' = s.' || COLUMN_NAME  || ' AND ~') || '~','AND ~~'), '~')  AS nat_key_join_t1\n",
                "\t , REPLACE(REPLACE(LISTAGG(' t2.' || COLUMN_NAME || ' = s.' || COLUMN_NAME  || ' AND ~') || '~','AND ~~'), '~')  AS nat_key_join_t2\n",
                "\t , REPLACE(REPLACE(LISTAGG(' nc.' || COLUMN_NAME || ' = s.' || COLUMN_NAME  || ' AND ~') || '~','AND ~~'), '~')  AS nat_key_join_nc\n",
                "\t , REPLACE(REPLACE(LISTAGG(' src.' || COLUMN_NAME || ' = tgt.' || COLUMN_NAME  || ' AND ~') || '~','AND ~~'), '~')  AS nat_key_join_src\n",
                "  FROM base\n",
                " ORDER BY ORDINAL_POSITION\n",
                "\"\"\"\n",
                "print(sql)\n",
                "\n",
                "cur.execute(sql)\n",
                "one_row = cur.fetchone()\n",
                "nat_key_select = one_row[0]\n",
                "nat_key_join = one_row[1]\n",
                "nat_key_join_t1 = one_row[2]\n",
                "nat_key_join_t2 = one_row[3]\n",
                "nat_key_join_nc = one_row[4]\n",
                "nat_key_join_src = one_row[5]\n",
                "\n",
                "print('nat_key_select:', nat_key_select)\n",
                "print('nat_key_join:', nat_key_join)\n",
                "print('nat_key_join_t1:', nat_key_join_t1)\n",
                "print('nat_key_join_t2:', nat_key_join_t2)\n",
                "print('nat_key_join_nc:', nat_key_join_nc)\n",
                "print('nat_key_join_src:', nat_key_join_src)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Type 1 change check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = \"\"\"\n",
                "WITH base AS\n",
                "(\n",
                "SELECT DISTINCT TOP 1000 ORDINAL_POSITION, COLUMN_NAME\n",
                "  FROM \"\"\" + src_database + \"\"\".INFORMATION_SCHEMA.\"COLUMNS\"\n",
                " WHERE COLUMN_NAME NOT IN (select trim(value) from table(split_to_table('\"\"\" + natural_key_columns + \"\"\"', ',')))\n",
                "   AND TABLE_SCHEMA = '\"\"\" + src_schema + \"\"\"'\n",
                "   AND TABLE_NAME = '\"\"\" + src_table + \"\"\"'\n",
                " ORDER BY ORDINAL_POSITION\n",
                ")\n",
                ", base2 AS\n",
                "(\n",
                "SELECT TRIM(LISTAGG('\\n NVL(CAST(r.' || column_name || ' AS VARCHAR),''-99999'') != NVL(CAST(s.' || column_name || ' AS VARCHAR),''-99999'')' || ' OR '), 'OR ') AS sql\n",
                "  FROM base\n",
                ")\n",
                "SELECT CASE WHEN TRIM(sql) = '' THEN ' 1=2 ' ELSE sql END AS ret_sql\n",
                "  FROM base2\n",
                "\"\"\"\n",
                "print(sql)\n",
                "\n",
                "cur.execute(sql)\n",
                "one_row = cur.fetchone()\n",
                "type_1_change_check = one_row[0]\n",
                "\n",
                "print(type_1_change_check)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Type 2 change check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = \"\"\"\n",
                "WITH base AS\n",
                "(\n",
                "SELECT DISTINCT TOP 1000 ORDINAL_POSITION, COLUMN_NAME\n",
                "  FROM \"\"\" + src_database + \"\"\".INFORMATION_SCHEMA.\"COLUMNS\"\n",
                " WHERE COLUMN_NAME IN (select trim(value) from table(split_to_table('\"\"\" + type_2_columns + \"\"\"', ',')))\n",
                "   AND TABLE_SCHEMA = '\"\"\" + src_schema + \"\"\"'\n",
                "   AND TABLE_NAME = '\"\"\" + src_table + \"\"\"'\n",
                " ORDER BY ORDINAL_POSITION\n",
                ")\n",
                ", base2 AS\n",
                "(\n",
                "SELECT TRIM(LISTAGG('\\n NVL(CAST(r.' || column_name || ' AS VARCHAR),''-99999'') != NVL(CAST(s.' || column_name || ' AS VARCHAR),''-99999'')' || ' OR '), 'OR ') AS sql\n",
                "  FROM base\n",
                ")\n",
                "SELECT CASE WHEN TRIM(sql) = '' THEN ' 1=2 ' ELSE sql END AS ret_sql\n",
                "  FROM base2\n",
                "\"\"\"\n",
                "print(sql)\n",
                "\n",
                "cur.execute(sql)\n",
                "one_row = cur.fetchone()\n",
                "type_2_change_check = one_row[0]\n",
                "\n",
                "print(type_2_change_check)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Staging columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = \"\"\"WITH base AS\n",
                "(\n",
                "SELECT DISTINCT TOP 1000 ORDINAL_POSITION, COLUMN_NAME\n",
                "  FROM \"\"\" + src_database + \"\"\".INFORMATION_SCHEMA.\"COLUMNS\"\n",
                " WHERE TABLE_SCHEMA = '\"\"\" + src_schema + \"\"\"'\n",
                "   AND TABLE_NAME = '\"\"\" + src_table + \"\"\"'\n",
                " ORDER BY ORDINAL_POSITION\n",
                ")\n",
                "SELECT TRIM(LISTAGG('s.' || COLUMN_NAME || '' || ', '), ', ')\n",
                "     , TRIM(LISTAGG( COLUMN_NAME || '' || ', '), ', ')\n",
                "     , TRIM(LISTAGG('src.' || COLUMN_NAME || '' || ', '), ', ')\n",
                "  FROM base;\n",
                "\"\"\"\n",
                "print(sql)\n",
                "cur.execute(sql)\n",
                "one_row = cur.fetchone()\n",
                "\n",
                "staging_columns = one_row[0]\n",
                "merge_insert_list = one_row[1]\n",
                "merge_output_list = one_row[2]\n",
                "\n",
                "print('staging_columns:' , staging_columns)\n",
                "print('merge_insert_list:' , merge_insert_list)\n",
                "print('merge_output_list:' , merge_output_list)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Merge update set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sql = \"\"\"\n",
                "WITH base AS\n",
                "(\n",
                "SELECT DISTINCT TOP 1000 ORDINAL_POSITION, COLUMN_NAME\n",
                "  FROM \"\"\" + src_database + \"\"\".INFORMATION_SCHEMA.\"COLUMNS\"\n",
                " WHERE COLUMN_NAME NOT IN (select trim(value) from table(split_to_table('\"\"\" + type_0_columns + \"\"\"', ',')))\n",
                "   AND COLUMN_NAME NOT IN (select trim(value) from table(split_to_table('\"\"\" + natural_key_columns + \"\"\"', ',')))  \n",
                "   AND TABLE_SCHEMA = '\"\"\" + src_schema + \"\"\"'\n",
                "   AND TABLE_NAME = '\"\"\" + src_table + \"\"\"'\n",
                " ORDER BY ORDINAL_POSITION\n",
                ")\n",
                "SELECT TRIM(LISTAGG('\\n ' || column_name || ' = CASE ChangeType WHEN ''Type 1'' THEN SRC.' || column_name || ' ELSE DST.' || column_name || ' END' || ' , '))\n",
                "FROM base\n",
                "\"\"\"\n",
                "print(sql)\n",
                "cur.execute(sql)\n",
                "one_row = cur.fetchone()\n",
                "\n",
                "merge_update_set = one_row[0]\n",
                "print('merge_update_set:' , merge_update_set)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create staging table\n",
                "### Determine type 2 changes (intra-day changes are treated as Type 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "CREATE OR REPLACE TEMPORARY TABLE staging AS\n",
                        "WITH type2 AS\n",
                        "\t(\n",
                        "\tSELECT s.DATABASE_NAME \n",
                        "\t\t , CASE WHEN CAST(r.ROW_UPDATE_DATE AS DATE) = CAST(GETDATE() AS DATE)\n",
                        "\t\t\t\tTHEN 'type1'\n",
                        "\t\t\t\tELSE 'type2'\n",
                        "\t\t   END AS Change\n",
                        "\t  FROM \"UTIL_DB\".\"INFORMATION_SCHEMA\".\"DATABASES\" s\n",
                        "\t  JOIN \"UTIL_DB\".\"METADATA\".\"D_DATABASES\" r\n",
                        "\t\tON  r.DATABASE_NAME = s.DATABASE_NAME \n",
                        "\t WHERE r.ROW_IS_CURRENT = 'Y'\n",
                        "\t   AND (\n",
                        " NVL(CAST(r.DATABASE_OWNER AS VARCHAR),'-99999') != NVL(CAST(s.DATABASE_OWNER AS VARCHAR),'-99999') OR \n",
                        " NVL(CAST(r.RETENTION_TIME AS VARCHAR),'-99999') != NVL(CAST(s.RETENTION_TIME AS VARCHAR),'-99999'))\n",
                        "\t)\n",
                        "// determine Type 1 changes\n",
                        ", type1 AS\n",
                        "  (\n",
                        "  SELECT s.DATABASE_NAME \n",
                        "\t   , 'type1' AS Change\n",
                        "\tFROM \"UTIL_DB\".\"INFORMATION_SCHEMA\".\"DATABASES\" s\n",
                        "\tJOIN \"UTIL_DB\".\"METADATA\".\"D_DATABASES\" r\n",
                        "\t  ON  r.DATABASE_NAME = s.DATABASE_NAME \n",
                        "   WHERE r.ROW_IS_CURRENT = 'Y'\n",
                        "\t AND (\n",
                        " NVL(CAST(r.DATABASE_OWNER AS VARCHAR),'-99999') != NVL(CAST(s.DATABASE_OWNER AS VARCHAR),'-99999') OR \n",
                        " NVL(CAST(r.IS_TRANSIENT AS VARCHAR),'-99999') != NVL(CAST(s.IS_TRANSIENT AS VARCHAR),'-99999') OR \n",
                        " NVL(CAST(r.COMMENT AS VARCHAR),'-99999') != NVL(CAST(s.COMMENT AS VARCHAR),'-99999') OR \n",
                        " NVL(CAST(r.CREATED AS VARCHAR),'-99999') != NVL(CAST(s.CREATED AS VARCHAR),'-99999') OR \n",
                        " NVL(CAST(r.LAST_ALTERED AS VARCHAR),'-99999') != NVL(CAST(s.LAST_ALTERED AS VARCHAR),'-99999') OR \n",
                        " NVL(CAST(r.RETENTION_TIME AS VARCHAR),'-99999') != NVL(CAST(s.RETENTION_TIME AS VARCHAR),'-99999'))\n",
                        "  )\n",
                        "// determine matches with no changes (all rows not caught above will be treated as type 0 - ignored in merge statement below)\n",
                        ", nochg AS\n",
                        "(\n",
                        "SELECT s.DATABASE_NAME \n",
                        "\t , 'nochg' AS Change\n",
                        "  FROM \"UTIL_DB\".\"INFORMATION_SCHEMA\".\"DATABASES\" s\n",
                        "  JOIN \"UTIL_DB\".\"METADATA\".\"D_DATABASES\" r\n",
                        "\tON  r.DATABASE_NAME = s.DATABASE_NAME \n",
                        " WHERE r.ROW_IS_CURRENT = 'Y'\n",
                        ")\n",
                        "// combine all the above CTEs and add no-matches from source\n",
                        "SELECT s.DATABASE_NAME, s.DATABASE_OWNER, s.IS_TRANSIENT, s.COMMENT, s.CREATED, s.LAST_ALTERED, s.RETENTION_TIME\n",
                        "\t , CASE WHEN t2.Change = 'type2' THEN 'Type 2'\n",
                        "\t\t\tWHEN t2.Change = 'type1' THEN 'Type 1'\n",
                        "\t\t\tWHEN t1.Change = 'type1' THEN 'Type 1'\n",
                        "\t\t\tWHEN nc.Change = 'nochg' THEN 'No Change'\n",
                        "\t\t\tELSE 'Insert'\n",
                        "\t   END AS ChangeType\n",
                        "  FROM \"UTIL_DB\".\"INFORMATION_SCHEMA\".\"DATABASES\" s\n",
                        "  LEFT JOIN \"UTIL_DB\".\"METADATA\".\"D_DATABASES\" r\n",
                        "\tON  r.DATABASE_NAME = s.DATABASE_NAME \n",
                        "  LEFT JOIN type1 t1\n",
                        "\tON  t1.DATABASE_NAME = s.DATABASE_NAME \n",
                        "  LEFT JOIN type2 t2\n",
                        "\tON  t2.DATABASE_NAME = s.DATABASE_NAME \n",
                        "  LEFT JOIN nochg nc\n",
                        "\tON  nc.DATABASE_NAME = s.DATABASE_NAME \n",
                        " WHERE IFNULL(r.ROW_IS_CURRENT, 'Y') = 'Y';\n",
                        "\n"
                    ]
                },
                {
                    "ename": "ProgrammingError",
                    "evalue": "SQL compilation error:\nObject 'UTIL_DB.METADATA.D_DATABASES' does not exist or not authorized.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-13-58b832b8844a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \"\"\"\n\u001b[0;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[0mone_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_row\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32mC:\\Python39\\lib\\site-packages\\snowflake\\connector\\cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params, _bind_stage, timeout, _exec_async, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _use_ijson, _is_put_get, _raise_put_get_error, _force_put_overwrite, file_stream)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;34m\"sfqid\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sfqid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             }\n\u001b[1;32m--> 768\u001b[1;33m             Error.errorhandler_wrapper(\n\u001b[0m\u001b[0;32m    769\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mProgrammingError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             )\n",
                        "\u001b[1;32mC:\\Python39\\lib\\site-packages\\snowflake\\connector\\errors.py\u001b[0m in \u001b[0;36merrorhandler_wrapper\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \"\"\"\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         handed_over = Error.hand_to_other_handler(\n\u001b[0m\u001b[0;32m    255\u001b[0m             \u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32mC:\\Python39\\lib\\site-packages\\snowflake\\connector\\errors.py\u001b[0m in \u001b[0;36mhand_to_other_handler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcursor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrorhandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32mC:\\Python39\\lib\\site-packages\\snowflake\\connector\\errors.py\u001b[0m in \u001b[0;36mdefault_errorhandler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mSnowflake\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m         raise error_class(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"msg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0merrno\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errno\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mProgrammingError\u001b[0m: SQL compilation error:\nObject 'UTIL_DB.METADATA.D_DATABASES' does not exist or not authorized."
                    ]
                }
            ],
            "source": [
                "sql = \"\"\"\n",
                "CREATE OR REPLACE TEMPORARY TABLE staging AS\n",
                "WITH type2 AS\n",
                "\t(\n",
                "\tSELECT \"\"\" + nat_key_select  + \"\"\"\n",
                "\t\t , CASE WHEN CAST(r.\"\"\" + row_update_date + \"\"\" AS DATE) = CAST(GETDATE() AS DATE)\n",
                "\t\t\t\tTHEN 'type1'\n",
                "\t\t\t\tELSE 'type2'\n",
                "\t\t   END AS Change\n",
                "\t  FROM \"\"\" + src_table_full + \"\"\" s\n",
                "\t  JOIN \"\"\" + tgt_table_full + \"\"\" r\n",
                "\t\tON \"\"\" + nat_key_join + \"\"\"\n",
                "\t WHERE r.\"\"\" + row_is_current + \"\"\" = 'Y'\n",
                "\t   AND (\"\"\" + type_2_change_check + \"\"\")\n",
                "\t)\n",
                "// determine Type 1 changes\n",
                ", type1 AS\n",
                "  (\n",
                "  SELECT \"\"\" + nat_key_select + \"\"\"\n",
                "\t   , 'type1' AS Change\n",
                "\tFROM \"\"\" + src_table_full + \"\"\" s\n",
                "\tJOIN \"\"\" + tgt_table_full + \"\"\" r\n",
                "\t  ON \"\"\" + nat_key_join + \"\"\"\n",
                "   WHERE r.\"\"\" + row_is_current + \"\"\" = 'Y'\n",
                "\t AND (\"\"\" + type_1_change_check + \"\"\")\n",
                "  )\n",
                "// determine matches with no changes (all rows not caught above will be treated as type 0 - ignored in merge statement below)\n",
                ", nochg AS\n",
                "(\n",
                "SELECT \"\"\" + nat_key_select + \"\"\"\n",
                "\t , 'nochg' AS Change\n",
                "  FROM \"\"\" + src_table_full + \"\"\" s\n",
                "  JOIN \"\"\" + tgt_table_full + \"\"\" r\n",
                "\tON \"\"\" + nat_key_join + \"\"\"\n",
                " WHERE r.\"\"\" + row_is_current + \"\"\" = 'Y'\n",
                ")\n",
                "// combine all the above CTEs and add no-matches from source\n",
                "SELECT \"\"\" + staging_columns + \"\"\"\n",
                "\t , CASE WHEN t2.Change = 'type2' THEN 'Type 2'\n",
                "\t\t\tWHEN t2.Change = 'type1' THEN 'Type 1'\n",
                "\t\t\tWHEN t1.Change = 'type1' THEN 'Type 1'\n",
                "\t\t\tWHEN nc.Change = 'nochg' THEN 'No Change'\n",
                "\t\t\tELSE 'Insert'\n",
                "\t   END AS ChangeType\n",
                "  FROM \"\"\" + src_table_full + \"\"\" s\n",
                "  LEFT JOIN \"\"\" + tgt_table_full + \"\"\" r\n",
                "\tON \"\"\" + nat_key_join + \"\"\"\n",
                "  LEFT JOIN type1 t1\n",
                "\tON \"\"\" + nat_key_join_t1 + \"\"\"\n",
                "  LEFT JOIN type2 t2\n",
                "\tON \"\"\" + nat_key_join_t2 + \"\"\"\n",
                "  LEFT JOIN nochg nc\n",
                "\tON \"\"\" + nat_key_join_nc + \"\"\"\n",
                " WHERE IFNULL(r.\"\"\" + row_is_current + \"\"\", 'Y') = 'Y';\n",
                "\"\"\"\n",
                "print(sql)\n",
                "cur.execute(sql)\n",
                "one_row = cur.fetchone()\n",
                "print(one_row[0])"
            ]
        }
    ],
    "metadata": {
        "extensions": {
            "azuredatastudio": {
                "version": 1,
                "views": []
            }
        },
        "interpreter": {
            "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
        },
        "kernelspec": {
            "display_name": "Python 3.9.6 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
